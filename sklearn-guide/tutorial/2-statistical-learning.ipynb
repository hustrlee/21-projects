{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计学习（Statistical Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计学习是什么？\n",
    "\n",
    "> 参考文献：[「统计学」「统计推断」「统计学习」有什么区别？](https://www.zhihu.com/question/23687389)\n",
    "\n",
    "**名词：**\n",
    "\n",
    "- 概率论：大千视界中，数据分布呈现出来的形状（分布函数、密度函数...）。\n",
    "- 数理统计：建立在各种分布的前提下，我们如何用少量的样本数据来推断总体的一些性质；或者推断两个样本是否来自一个总体；等等...\n",
    "- 统计推断：根据样本数据对总体进行统计推断。包括：「参数估计问题」、「假设检验问题」两个方向。\n",
    "- 统计学：概率论 + 数理统计 = 统计学\n",
    "- 「统计学习」：在 machine learning 学科下，利用统计学知识和数值型数据来进行机器学习（也称之为：优化）。\n",
    "\n",
    "**几者之间的关系：**\n",
    "\n",
    "- 「概率论」是「数理统计」的理论基础\n",
    "- 学「数理统计」等于在学习如何进行「统计推断」\n",
    "- 「概率论」+「数理统计」=「统计学」\n",
    "- 「统计推理」是学习「统计学」的目的，「统计学」是「统计推理」的基础\n",
    "- 「回归模型」是「统计学」中最常用的模型\n",
    "- 「回归模型」参数求解的主要方法包括：「最小二乘（OLS）」和「最大似然估计（MLE）」\n",
    "- OLS 和 MLE 的求解实质上是一个「数值优化（optimization）」问题\n",
    "- 机器学习的一个方向就是：让机器求解一个或多个「数值优化」问题，这种思路称之为「统计学习」\n",
    "- 机器学习的另一个方向是：通过逻辑判断的方法来求解问题，称之为「内容学习（Concept Learning）」\n",
    "- 「统计学习」关注的是：最小化预测误差\n",
    "\n",
    "**统计学习方法特点：**\n",
    "\n",
    "| 方法           | 适用问题         | 模型特点                                           | 模型类型 | 学习策略                           | 损失函数             | 学习算法                               |\n",
    "| -------------- | ---------------- | -------------------------------------------------- | -------- | ---------------------------------- | -------------------- | -------------------------------------- |\n",
    "| 感知机         | 二分类           | 分离超平面                                         | 判别     | 极小化误分点到超平面的距离         | 误分点到超平面的距离 | 随机梯度下降                           |\n",
    "| K 近邻         | 多分类、回归     | 特征空间、样本点                                   | 判别     | —                                  | —                    | —                                      |\n",
    "| 朴素贝叶斯     | 多分类           | 特征与类别的联合概率分布，条件独立假设             | 生成     | 极大似然估计，极大后验概率估计     | 对数似然损失         | 概率计算公式，EM 算法                  |\n",
    "| 决策树         | 多分类、回归     | 分类树，回归树                                     | 判别     | 正则化的极大似然估计               | 对数似然损失         | 特征选择，生成，剪枝                   |\n",
    "| 逻辑斯蒂回归   | 多分类           | 特征条件下类别的条件概率分布，对数线性模型         | 判别     | 极大似然估计，正则化的极大似然估计 | 逻辑斯蒂损失         | 改进的迭代尺度算法，梯度下降，拟牛顿法 |\n",
    "| 支持向量机     | 二分类           | 分离超平面，核技巧                                 | 判别     | 极小化正则合页损失，软间隔最大化   | 合页损失             | 序列最小最优化算法（SMO）              |\n",
    "| 集成方法       | 二分类           | 弱分类器的线性组合                                 | 判别     | 极小化加法模型的指数损失           | 指数损失             | 前向分布加法算法                       |\n",
    "| EM 算法        | 概率模型参数估计 | 含隐变量概率模型                                   | —        | 极大似然估计，极大后验概率估计     | 对数似然损失         | 迭代算法                               |\n",
    "| 隐马尔可夫模型 | 标注             | 观测序列与状态序列的联合概率分布模型               | 生成     | 极大似然估计，极大后验概率估计     | 对数似然损失         | 概率计算公式，EM 算法                  |\n",
    "| 条件随机场     | 标注             | 状态序列条件下观测序列的条件概率分布，对数线性模型 | 判别     | 极大似然估计，正则化极大似然估计   | 对数似然损失         | 改进的迭代尺度算法，梯度下降，拟牛顿法 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集与估计器\n",
    "\n",
    "### 数据集\n",
    "\n",
    "scikit-learn 的数据集是一个 2d 数组，它们被理解为多维观测（multi-dimensional observations）的列表（list）。我们称数组的第一个轴为样本轴，第二个轴为特征轴。\n",
    "\n",
    "如果原始数据不是 `(n_samples, n_features)` 格式的，那么在交给 scikit-learn 进行学习前，需要重新格式化数据。\n",
    "\n",
    "例如：digits dataset。原始数据是：`(1792, 8, 8)` 格式的，需要通过 `reshape()` 转换为 `(1797, 64)` 格式的数据。\n",
    "\n",
    "> 原始的 digits dataset 的格式为：\n",
    "> - 训练集：`(60000, 28, 28)`\n",
    "> - 测试集：`(10000, 28, 28)`\n",
    ">\n",
    "> 在 scikit-learn 中，对该数据集进行了裁剪。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits.images.shape: (1797, 8, 8)\n",
      "data.shape: (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "print(\"digits.images.shape:\", digits.images.shape)\n",
    "\n",
    "data = digits.images.reshape(digits.images.shape[0], -1)\n",
    "print(\"data.shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 实际上，scikit-learn 的内置数据集已经格式化好了数据。上例中，`digits.data` 就已经是格式化好的数据，`digits.images` 是原始数据。上面的代码片段，仅仅是为了演示如何格式化数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 估计器\n",
    "\n",
    "**训练（Fitting data）**：估计器（`estimator`）从数据中进行学习，完成*分类*、*回归*、*聚类*、和*转换*。所有的估计器都实现了一个 `fit()` 方法，来完成模型的训练。\n",
    "\n",
    "**转换（Transform）**：从原始数据中*提取*、*筛选*有用的特征。\n",
    "\n",
    "**估计器参数（Estimator parameters）**：所有的参数可以在初始化的时候设定，也可以在后面进行修改。\n",
    "\n",
    "**估计参数（Estimated parameters）**：训练完成后得到的模型参数，也可以通过估计器的属性来获得，这些属性以“*下划线*”结尾。例如：`estimator.estimated_param_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习：从高维观测（high-dimensional observations）进行预测\n",
    "\n",
    "- 监督学习（Supervised learning）\n",
    "- 观测数据（Observations)\n",
    "- 目标/标签（Target/Label）\n",
    "\n",
    "### 近邻算法（Nearest Neighbor）和维度灾难（curse of dimensonality）\n",
    "\n",
    "从直观感觉上，随着特征维度的增加，分类器会越来越准；但事实上随着特征维度的增加，分类器会越来越不准，同时带来很多其它问题，包括：\n",
    "\n",
    "- 维度的增加，会导致模型的“*泛化*”能力下降。泛化能力下降，被称为“*过拟合*”。\n",
    "- 理论上，可以通过增加样本数来改善模型的泛化能力；但是，随着维度的增加，所需的样本数成指数增加。当维度增加到 20d 时，理论上 KNN 算法所需的样本数超过了互联网的总数据量。\n",
    "- 维度的增加，会导致估计器的参数量急剧增加。\n",
    "\n",
    "可以通过“*降维*”来解决维度灾难，常见的降维方法包括：\n",
    "\n",
    "- 特征选择\n",
    "- 特征提取\n",
    "- 交叉验证\n",
    "\n",
    "> 参考文献：[机器学习中的维度灾难](https://zhuanlan.zhihu.com/p/26945814)\n",
    "\n",
    "### 线性模型：从回归到稀疏（Sparsity）\n",
    "\n",
    "#### 线性回归模型\n",
    "\n",
    "$y=X\\beta+\\epsilon$\n",
    "\n",
    "- $X$：data\n",
    "- $y$：target\n",
    "- $\\beta$：系数\n",
    "- $\\epsilon$：观测噪声（Observation noise）\n",
    "\n",
    "#### 特征缩减（Shrinkage）\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
