{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计学习（Statistical Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计学习是什么？\n",
    "\n",
    "> 参考文献：[「统计学」「统计推断」「统计学习」有什么区别？](https://www.zhihu.com/question/23687389)\n",
    "\n",
    "**名词：**\n",
    "\n",
    "- 概率论：大千视界中，数据分布呈现出来的形状（分布函数、密度函数...）。\n",
    "- 数理统计：建立在各种分布的前提下，我们如何用少量的样本数据来推断总体的一些性质；或者推断两个样本是否来自一个总体；等等...\n",
    "- 统计推断：根据样本数据对总体进行统计推断。包括：「参数估计问题」、「假设检验问题」两个方向。\n",
    "- 统计学：概率论 + 数理统计 = 统计学\n",
    "- 「统计学习」：在 machine learning 学科下，利用统计学知识和数值型数据来进行机器学习（也称之为：优化）。\n",
    "\n",
    "**几者之间的关系：**\n",
    "\n",
    "- 「概率论」是「数理统计」的理论基础\n",
    "- 学「数理统计」等于在学习如何进行「统计推断」\n",
    "- 「概率论」+「数理统计」=「统计学」\n",
    "- 「统计推理」是学习「统计学」的目的，「统计学」是「统计推理」的基础\n",
    "- 「回归模型」是「统计学」中最常用的模型\n",
    "- 「回归模型」参数求解的主要方法包括：「最小二乘（OLS）」和「最大似然估计（MLE）」\n",
    "- OLS 和 MLE 的求解实质上是一个「数值优化（optimization）」问题\n",
    "- 机器学习的一个方向就是：让机器求解一个或多个「数值优化」问题，这种思路称之为「统计学习」\n",
    "- 机器学习的另一个方向是：通过逻辑判断的方法来求解问题，称之为「内容学习（Concept Learning）」\n",
    "- 「统计学习」关注的是：最小化预测误差\n",
    "\n",
    "**统计学习方法特点：**\n",
    "\n",
    "| 方法           | 适用问题         | 模型特点                                           | 模型类型 | 学习策略                           | 损失函数             | 学习算法                               |\n",
    "| -------------- | ---------------- | -------------------------------------------------- | -------- | ---------------------------------- | -------------------- | -------------------------------------- |\n",
    "| 感知机         | 二分类           | 分离超平面                                         | 判别     | 极小化误分点到超平面的距离         | 误分点到超平面的距离 | 随机梯度下降                           |\n",
    "| K 近邻         | 多分类、回归     | 特征空间、样本点                                   | 判别     | —                                  | —                    | —                                      |\n",
    "| 朴素贝叶斯     | 多分类           | 特征与类别的联合概率分布，条件独立假设             | 生成     | 极大似然估计，极大后验概率估计     | 对数似然损失         | 概率计算公式，EM 算法                  |\n",
    "| 决策树         | 多分类、回归     | 分类树，回归树                                     | 判别     | 正则化的极大似然估计               | 对数似然损失         | 特征选择，生成，剪枝                   |\n",
    "| 逻辑斯蒂回归   | 多分类           | 特征条件下类别的条件概率分布，对数线性模型         | 判别     | 极大似然估计，正则化的极大似然估计 | 逻辑斯蒂损失         | 改进的迭代尺度算法，梯度下降，拟牛顿法 |\n",
    "| 支持向量机     | 二分类           | 分离超平面，核技巧                                 | 判别     | 极小化正则合页损失，软间隔最大化   | 合页损失             | 序列最小最优化算法（SMO）              |\n",
    "| 集成方法       | 二分类           | 弱分类器的线性组合                                 | 判别     | 极小化加法模型的指数损失           | 指数损失             | 前向分布加法算法                       |\n",
    "| EM 算法        | 概率模型参数估计 | 含隐变量概率模型                                   | —        | 极大似然估计，极大后验概率估计     | 对数似然损失         | 迭代算法                               |\n",
    "| 隐马尔可夫模型 | 标注             | 观测序列与状态序列的联合概率分布模型               | 生成     | 极大似然估计，极大后验概率估计     | 对数似然损失         | 概率计算公式，EM 算法                  |\n",
    "| 条件随机场     | 标注             | 状态序列条件下观测序列的条件概率分布，对数线性模型 | 判别     | 极大似然估计，正则化极大似然估计   | 对数似然损失         | 改进的迭代尺度算法，梯度下降，拟牛顿法 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
